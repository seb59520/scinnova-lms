# ğŸ¯ Fil Rouge Databricks : E-commerce â€” "Comprendre & PrÃ©dire la Performance Commerciale"

## ğŸ“‹ Vue d'ensemble

Ce fil rouge couvre le parcours complet **Big Data â†’ Data Science â†’ Machine Learning** Ã  travers un cas mÃ©tier concret : l'analyse et la prÃ©diction de la performance commerciale d'un e-commerce.

### ğŸ“ Objectifs pÃ©dagogiques

Ã€ l'issue de ce fil rouge, les participants sauront :

1. **Big Data** : IngÃ©rer et traiter des donnÃ©es massives avec Spark
2. **Data Science** : Explorer, fiabiliser et prÃ©parer des donnÃ©es pour le ML
3. **Machine Learning** : Construire, Ã©valuer et dÃ©ployer un modÃ¨le de classification

---

## ğŸ“Š Dataset : `sales_2M.csv`

| Colonne      | Type    | Description                                   |
|--------------|---------|-----------------------------------------------|
| `order_id`   | String  | Identifiant unique de commande (ORD-0000001)  |
| `order_date` | Date    | Date de la commande (2023-01-01 Ã  2024-12-31) |
| `product`    | String  | Nom du produit (Smartphone, Laptop, TV, etc.) |
| `category`   | String  | CatÃ©gorie (Ã‰lectronique, Informatique, Audio) |
| `country`    | String  | Pays (France, Allemagne, Espagne, etc.)       |
| `price`      | Float   | Prix unitaire (â‚¬)                             |
| `quantity`   | Integer | QuantitÃ© commandÃ©e                            |
| `channel`    | String  | Canal de vente (Web, Mobile, Magasin)         |
| `payment`    | String  | Moyen de paiement (Carte, Paypal, etc.)       |

**CaractÃ©ristiques clÃ©s :**
- 2 millions de lignes
- PÃ©riode : 2 ans (730 jours)
- SaisonnalitÃ© : pics en novembre/dÃ©cembre
- Distribution rÃ©aliste des pays (France dominante Ã  34%)

---

## ğŸ“š Structure du Cours

### Notebook 1 â€” BIG DATA (45-60 min)
**"Passer du CSV brut Ã  une table exploitable"**

| Section | DurÃ©e | Contenu |
|---------|-------|---------|
| Introduction | 5 min | Contexte, objectifs, prÃ©sentation du dataset |
| Lecture Spark | 10 min | Chargement CSV, infÃ©rence de schÃ©ma |
| Normalisation | 10 min | Typage, calcul du revenue |
| Delta Lake | 10 min | Persistance optimisÃ©e, time travel |
| Analyses BI | 15 min | CA par pays, top produits, tendances |
| SynthÃ¨se | 5 min | Points clÃ©s, transition vers Notebook 2 |

### Notebook 2 â€” DATA SCIENCE (45-60 min)
**"Rendre la donnÃ©e fiable + construire une cible ML"**

| Section | DurÃ©e | Contenu |
|---------|-------|---------|
| QualitÃ© des donnÃ©es | 10 min | ContrÃ´le nulls, valeurs aberrantes |
| EDA | 15 min | Distributions, corrÃ©lations, insights |
| Feature Engineering | 15 min | Variables temporelles, cible ML |
| PrÃ©paration ML | 10 min | SÃ©lection colonnes, encodage prÃ©vu |
| SynthÃ¨se | 5 min | Points clÃ©s, transition vers Notebook 3 |

### Notebook 3 â€” MACHINE LEARNING (45-60 min)
**"EntraÃ®ner, Ã©valuer, scorer"**

| Section | DurÃ©e | Contenu |
|---------|-------|---------|
| Split Train/Test | 5 min | StratÃ©gie de sÃ©paration |
| Pipeline ML | 15 min | Encodage, assemblage, modÃ¨le |
| EntraÃ®nement | 10 min | Fit du modÃ¨le LogisticRegression |
| Ã‰valuation | 15 min | AUC, matrice de confusion |
| Scoring & InterprÃ©tation | 10 min | PrÃ©dictions, recommandations mÃ©tier |
| Extensions | 5 min | MLflow, modÃ¨les avancÃ©s |

---

## ğŸš€ PrÃ©requis Techniques

### Environnement Databricks
- Cluster avec Spark 3.x
- Runtime ML recommandÃ©
- Au moins 4 workers pour le traitement des 2M lignes

### Upload du Dataset
1. Aller dans **Data** > **Create Table** > **Upload File**
2. Uploader `sales_2M.csv`
3. Noter le chemin (ex: `dbfs:/FileStore/tables/sales_2M.csv`)

---

## ğŸ’¡ Questions Ã  Poser aux Participants

### Notebook 1 - Big Data
- "Pourquoi Spark plutÃ´t que Pandas pour 2M lignes ?"
- "Quel avantage de Delta Lake vs CSV pour les analyses rÃ©pÃ©tÃ©es ?"
- "Comment interprÃ©ter les variations de CA par pays ?"

### Notebook 2 - Data Science
- "Quelles colonnes pourraient contenir des valeurs aberrantes ?"
- "Pourquoi crÃ©er une cible binaire plutÃ´t que prÃ©dire le revenue exact ?"
- "Quelles autres features pourrait-on crÃ©er ?"

### Notebook 3 - Machine Learning
- "Pourquoi 80/20 pour le split ?"
- "Que signifie un AUC de 0.85 ?"
- "Comment utiliser ce modÃ¨le en production ?"

---

## âš ï¸ PiÃ¨ges Courants

| PiÃ¨ge | Solution |
|-------|----------|
| Oubli du `handleInvalid="keep"` | Valeurs inconnues en test â†’ erreur |
| Colonnes non typÃ©es | Toujours caster aprÃ¨s lecture CSV |
| Fuite de donnÃ©es (data leakage) | Ne jamais calculer stats sur tout avant split |
| Overfitting | Toujours Ã©valuer sur test, pas sur train |

---

## ğŸ“ˆ Extensions Possibles

### Niveau IntermÃ©diaire
- Ajouter des features : `is_weekend`, `week_of_year`, `basket_size`
- Tester `RandomForestClassifier` au lieu de LogisticRegression
- Comparer les AUC entre modÃ¨les

### Niveau AvancÃ©
- IntÃ©grer MLflow pour le tracking
- Cross-validation avec `CrossValidator`
- Feature importance et SHAP values
- DÃ©ploiement avec Model Serving

---

## ğŸ“ Fichiers du Cours

```
databricks-fil-rouge/
â”œâ”€â”€ README.md                    # Ce fichier
â”œâ”€â”€ 01_Big_Data_Ingestion.py    # Notebook 1
â”œâ”€â”€ 02_Data_Science_EDA.py      # Notebook 2
â”œâ”€â”€ 03_Machine_Learning.py      # Notebook 3
â””â”€â”€ solutions/                   # Solutions complÃ¨tes (optionnel)
```

---

## ğŸ¯ CompÃ©tences ValidÃ©es

Ã€ la fin du fil rouge, les participants peuvent affirmer :

> âœ… **Big Data** : "Je sais ingÃ©rer et traiter des donnÃ©es Ã  grande Ã©chelle avec Spark"
>
> âœ… **Data Science** : "Je sais explorer, nettoyer et prÃ©parer des donnÃ©es pour le ML"  
>
> âœ… **Machine Learning** : "Je sais entraÃ®ner un modÃ¨le, l'Ã©valuer et produire des recommandations actionnables"

---

*Fil rouge crÃ©Ã© pour la formation Data Science & Big Data â€” Databricks*

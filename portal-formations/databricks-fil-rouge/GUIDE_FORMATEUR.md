# üë®‚Äçüè´ Guide Formateur ‚Äî Fil Rouge Databricks

## üìã Vue d'ensemble de la session

| √âl√©ment | D√©tail |
|---------|--------|
| **Dur√©e totale** | 2h30 - 3h (avec pauses) |
| **Public cible** | Data Analysts, futurs Data Scientists |
| **Pr√©requis** | SQL de base, notions Python |
| **Format** | TP guid√© + exercices pratiques |

---

## ‚è±Ô∏è Planning Minute par Minute

### üîµ Notebook 1 ‚Äî Big Data (50 min)

| Temps | Section | Contenu | Action Formateur |
|-------|---------|---------|------------------|
| 0:00 | Introduction | Contexte e-commerce, objectifs | Pr√©senter le cas m√©tier |
| 0:05 | 1Ô∏è‚É£ Lecture CSV | Charger le fichier, sch√©ma | Expliquer `inferSchema` |
| 0:15 | 2Ô∏è‚É£ Normalisation | Types, calcul revenue | **QUESTION 1** |
| 0:25 | 3Ô∏è‚É£ Delta Lake | √âcriture table | Montrer le time travel |
| 0:35 | 4Ô∏è‚É£ Analyses BI | CA pays, top produits | Faire interpr√©ter les graphes |
| 0:45 | Synth√®se | R√©cap + transition | **QUESTION 2** |
| 0:50 | Pause | 10 minutes | ‚òï |

### üü¢ Notebook 2 ‚Äî Data Science (50 min)

| Temps | Section | Contenu | Action Formateur |
|-------|---------|---------|------------------|
| 1:00 | Introduction | Objectif : pr√©parer le ML | Expliquer le r√¥le DS |
| 1:05 | 2Ô∏è‚É£ Qualit√© | Nulls, aberrations | **QUESTION 3** |
| 1:15 | 3Ô∏è‚É£ EDA | Distributions, patterns | Faire analyser les graphes |
| 1:30 | 4Ô∏è‚É£ Cible ML | high_value_order | **QUESTION 4** |
| 1:40 | 5Ô∏è‚É£ Features | S√©lection colonnes | Expliquer le feature leakage |
| 1:50 | Synth√®se | R√©cap + transition | |
| 1:55 | Pause | 10 minutes | ‚òï |

### üü† Notebook 3 ‚Äî Machine Learning (55 min)

| Temps | Section | Contenu | Action Formateur |
|-------|---------|---------|------------------|
| 2:05 | Introduction | Objectif : classifier | Rappeler le contexte |
| 2:10 | 2Ô∏è‚É£ Split | Train/Test 80/20 | **QUESTION 5** |
| 2:15 | 3Ô∏è‚É£ Pipeline | Encodage, assemblage | Sch√©ma au tableau |
| 2:30 | 4Ô∏è‚É£ Entra√Ænement | Fit du mod√®le | Temps d'attente ‚Üí discussion |
| 2:35 | 5Ô∏è‚É£ √âvaluation | AUC, confusion | **QUESTION 6** |
| 2:45 | 6Ô∏è‚É£ Scoring | Pr√©dictions | Interpr√©ter les scores |
| 2:55 | 7Ô∏è‚É£ M√©tier | Recommandations | Exercice de synth√®se |
| 3:00 | Cl√¥ture | Synth√®se fil rouge | R√©cap 3 comp√©tences |

---

## ‚ùì Questions Cl√©s √† Poser

### QUESTION 1 ‚Äî Pourquoi normaliser les types ?
**Moment** : Apr√®s la section 2 du Notebook 1

**Poser** : "Pourquoi Spark a-t-il besoin qu'on caste explicitement les colonnes ?"

**R√©ponse attendue** :
- `inferSchema` n'est pas toujours fiable (string vs int)
- Les calculs num√©riques √©chouent sur des strings
- Performance : les types corrects = moins de m√©moire

**Si silence** : "Que se passe-t-il si on multiplie une string par un int ?"

---

### QUESTION 2 ‚Äî Avantage de Delta Lake
**Moment** : Fin du Notebook 1

**Poser** : "Pourquoi Delta plut√¥t que laisser le CSV ?"

**R√©ponse attendue** :
- Compression (moins de stockage)
- Sch√©ma enforc√© (pas de surprise)
- Time travel (audit, rollback)
- Updates possibles (ACID)

**Si silence** : "Imaginez qu'on doit corriger 1000 lignes... en CSV vs Delta ?"

---

### QUESTION 3 ‚Äî Importance de la qualit√©
**Moment** : Section Qualit√© du Notebook 2

**Poser** : "Quels probl√®mes de qualit√© pourrait-on trouver en production ?"

**R√©ponse attendue** :
- Nulls (champs manquants)
- Outliers (prix n√©gatif, quantit√© 0)
- Doublons (commande enregistr√©e 2x)
- Incoh√©rences (date future)

**Si silence** : "Que se passe-t-il si 10% des prix sont √† NULL ?"

---

### QUESTION 4 ‚Äî Choix de la cible
**Moment** : Apr√®s cr√©ation de `high_value_order`

**Poser** : "Pourquoi cr√©er une cible binaire plut√¥t que pr√©dire le revenue exact ?"

**R√©ponse attendue** :
- Classification = plus simple √† interpr√©ter
- M√©tier : "grosse commande oui/non" = d√©cision claire
- Moins sensible aux outliers extr√™mes
- R√©sultats actionnables (seuil = action)

**Si silence** : "Qu'est-ce qui est plus utile pour le marketing : pr√©dire 847.32‚Ç¨ ou dire 'client VIP probable' ?"

---

### QUESTION 5 ‚Äî Pourquoi le split Train/Test ?
**Moment** : D√©but Notebook 3

**Poser** : "Pourquoi ne pas entra√Æner sur 100% des donn√©es ?"

**R√©ponse attendue** :
- √âvaluer sur donn√©es non vues = vrai test
- √âviter l'overfitting (apprendre par c≈ìur)
- Simuler l'utilisation r√©elle
- G√©n√©ralisation vs m√©morisation

**Pi√®ge √† d√©tecter** : "On peut avoir un mod√®le parfait sur train et nul sur test"

---

### QUESTION 6 ‚Äî Interpr√©ter l'AUC
**Moment** : Apr√®s affichage de l'AUC

**Poser** : "Notre AUC est de 0.85. C'est bien ou pas ?"

**R√©ponse attendue** :
- 0.5 = al√©atoire, inutile
- 0.7-0.8 = acceptable
- 0.8-0.9 = bon
- > 0.9 = excellent

**Puis** : "Que signifie concr√®tement un AUC de 0.85 ?"

**R√©ponse** : "Dans 85% des cas, le mod√®le classe correctement un positif au-dessus d'un n√©gatif"

---

## ‚ö†Ô∏è Pi√®ges Courants & Solutions

### Pi√®ge 1 : "Mon CSV ne charge pas"
**Sympt√¥me** : `AnalysisException: Path does not exist`

**Diagnostic** :
```python
dbutils.fs.ls("dbfs:/FileStore/")  # V√©rifier le chemin
```

**Solution** : Adapter le PATH dans le notebook

---

### Pi√®ge 2 : "Erreur StringIndexer sur test"
**Sympt√¥me** : `Unseen label: XYZ`

**Cause** : Valeur pr√©sente dans test mais pas dans train

**Solution** : Toujours utiliser `handleInvalid="keep"`

---

### Pi√®ge 3 : "Mon mod√®le a un AUC de 0.99"
**Sympt√¥me** : AUC "trop beau"

**Cause probable** : Fuite de donn√©es (data leakage)

**V√©rifier** :
- Est-ce que `revenue` est dans les features ? (interdit !)
- Le split est-il fait avant les transformations ?

---

### Pi√®ge 4 : "Le notebook met 20 minutes"
**Sympt√¥me** : Cellules tr√®s lentes

**Causes possibles** :
- Cluster non d√©marr√©
- Trop petit cluster (1 worker)
- Collect() sur 2M lignes

**Solution** : Utiliser `display()` au lieu de `collect()`, v√©rifier le cluster

---

### Pi√®ge 5 : "Mon accuracy est de 80%"
**Sympt√¥me** : "C'est bien non ?"

**Pi√®ge p√©dagogique** : Avec 80% de classe 0, pr√©dire toujours 0 = 80% accuracy !

**Message** : "L'accuracy seule est trompeuse. Regardez precision/recall/AUC"

---

## üí¨ Phrases Cl√©s √† Transmettre

### Big Data
> "Spark ne charge pas tout en m√©moire ‚Äî il distribue le travail. C'est √ßa, le Big Data."

> "Delta Lake = CSV + superpowers. Transactions, versioning, performance."

### Data Science
> "Garbage in, garbage out. La qualit√© des donn√©es d√©termine la qualit√© du mod√®le."

> "Le feature engineering, c'est transformer votre connaissance m√©tier en colonnes."

### Machine Learning
> "Un mod√®le n'est utile que s'il produit des d√©cisions actionnables."

> "Toujours √©valuer sur des donn√©es non vues. Sinon, vous testez la m√©moire, pas l'intelligence."

---

## üìä Tableau de Synth√®se Final

√Ä afficher/projeter en conclusion :

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                 FIL ROUGE : R√âCAPITULATIF                    ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ    BIG DATA      ‚îÇ   DATA SCIENCE    ‚îÇ   MACHINE LEARNING    ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ ‚úÖ Spark         ‚îÇ ‚úÖ Qualit√©        ‚îÇ ‚úÖ Pipeline           ‚îÇ
‚îÇ ‚úÖ Delta Lake    ‚îÇ ‚úÖ EDA            ‚îÇ ‚úÖ Train/Test         ‚îÇ
‚îÇ ‚úÖ Agr√©gations   ‚îÇ ‚úÖ Features       ‚îÇ ‚úÖ √âvaluation         ‚îÇ
‚îÇ                  ‚îÇ ‚úÖ Cible ML       ‚îÇ ‚úÖ Scoring            ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ "Je sais         ‚îÇ "Je sais rendre   ‚îÇ "Je sais produire     ‚îÇ
‚îÇ traiter √†        ‚îÇ la donn√©e         ‚îÇ des pr√©dictions       ‚îÇ
‚îÇ l'√©chelle"       ‚îÇ exploitable"      ‚îÇ actionnables"         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üéØ Crit√®res de R√©ussite

### Pour le participant
- [ ] A cr√©√© la table Delta avec succ√®s
- [ ] Comprend la diff√©rence CSV/Delta
- [ ] A cr√©√© la cible `high_value_order`
- [ ] A obtenu un AUC > 0.7
- [ ] Sait interpr√©ter la matrice de confusion
- [ ] Propose une recommandation m√©tier

### Pour le formateur
- [ ] Chaque question cl√© a √©t√© pos√©e
- [ ] Les pi√®ges ont √©t√© anticip√©s
- [ ] La synth√®se finale a √©t√© faite
- [ ] Le lien th√©orie/pratique est clair

---

## üìö Ressources Compl√©mentaires

### Documentation
- [Spark SQL Guide](https://spark.apache.org/docs/latest/sql-programming-guide.html)
- [Delta Lake Quickstart](https://docs.delta.io/latest/quick-start.html)
- [Spark ML Pipeline](https://spark.apache.org/docs/latest/ml-pipeline.html)

### Exercices Avanc√©s
- Ajouter MLflow pour le tracking
- Impl√©menter un mod√®le Random Forest
- Faire une cross-validation
- Calculer les feature importances

---

*Guide formateur ‚Äî Fil Rouge Big Data / Data Science / ML*

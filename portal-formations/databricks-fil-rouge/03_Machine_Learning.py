# Databricks notebook source
# MAGIC %md
# MAGIC # ğŸ¤– Notebook 3 â€” MACHINE LEARNING : ModÃ¨le, Ã‰valuation, Scoring
# MAGIC 
# MAGIC ## ğŸ¯ Objectif
# MAGIC **EntraÃ®ner un modÃ¨le de classification, l'Ã©valuer et produire des prÃ©dictions actionnables**
# MAGIC 
# MAGIC ---
# MAGIC 
# MAGIC ### Ce que vous allez apprendre
# MAGIC 1. Construire un pipeline ML complet (encodage + modÃ¨le)
# MAGIC 2. EntraÃ®ner un modÃ¨le de classification (Logistic Regression)
# MAGIC 3. Ã‰valuer les performances (AUC, matrice de confusion)
# MAGIC 4. Scorer de nouvelles donnÃ©es et interprÃ©ter les rÃ©sultats
# MAGIC 
# MAGIC ### DurÃ©e estimÃ©e : 45-60 minutes
# MAGIC 
# MAGIC ---
# MAGIC 
# MAGIC ## ğŸ“Š Contexte MÃ©tier
# MAGIC 
# MAGIC L'Ã©quipe Marketing veut utiliser votre modÃ¨le pour :
# MAGIC - **Identifier** les commandes Ã  forte valeur dÃ¨s leur crÃ©ation
# MAGIC - **Prioriser** le service client pour ces commandes
# MAGIC - **DÃ©clencher** des offres de fidÃ©lisation ciblÃ©es
# MAGIC 
# MAGIC Vous devez livrer un modÃ¨le fiable avec des mÃ©triques claires.

# COMMAND ----------

# MAGIC %md
# MAGIC ## 1ï¸âƒ£ Chargement du Dataset ML

# COMMAND ----------

# Chargement du dataset prÃ©parÃ© dans le Notebook 2
ml_df = spark.table("sales_ml_ready")

print(f"ğŸ“Š Dataset ML : {ml_df.count():,} lignes")
ml_df.printSchema()

# COMMAND ----------

display(ml_df.limit(10))

# COMMAND ----------

# VÃ©rification de la distribution de la cible
display(ml_df.groupBy("high_value_order").count())

# COMMAND ----------

# MAGIC %md
# MAGIC ## 2ï¸âƒ£ Split Train / Test
# MAGIC 
# MAGIC ### StratÃ©gie
# MAGIC - **80%** pour l'entraÃ®nement (apprentissage des patterns)
# MAGIC - **20%** pour le test (Ã©valuation sur donnÃ©es non vues)
# MAGIC 
# MAGIC âš ï¸ Le `seed=42` garantit la reproductibilitÃ©

# COMMAND ----------

# Split stratifiÃ© 80/20
train, test = ml_df.randomSplit([0.8, 0.2], seed=42)

print(f"ğŸ“Š Train : {train.count():,} lignes")
print(f"ğŸ“Š Test  : {test.count():,} lignes")

# COMMAND ----------

# VÃ©rification de la distribution dans chaque set
print("Distribution Train :")
display(train.groupBy("high_value_order").count())

print("Distribution Test :")
display(test.groupBy("high_value_order").count())

# COMMAND ----------

# MAGIC %md
# MAGIC ## 3ï¸âƒ£ Construction du Pipeline ML
# MAGIC 
# MAGIC ### Architecture du Pipeline
# MAGIC 
# MAGIC ```
# MAGIC [DonnÃ©es brutes]
# MAGIC      â†“
# MAGIC [StringIndexer] â†’ Convertit les catÃ©gories en indices numÃ©riques
# MAGIC      â†“
# MAGIC [OneHotEncoder] â†’ Transforme les indices en vecteurs binaires
# MAGIC      â†“
# MAGIC [VectorAssembler] â†’ Combine toutes les features en un vecteur unique
# MAGIC      â†“
# MAGIC [LogisticRegression] â†’ ModÃ¨le de classification
# MAGIC      â†“
# MAGIC [PrÃ©dictions]
# MAGIC ```

# COMMAND ----------

from pyspark.ml import Pipeline
from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler
from pyspark.ml.classification import LogisticRegression

# DÃ©finition des colonnes
cat_cols = ["country", "channel", "payment", "category", "product"]
num_cols = ["price", "quantity", "month", "dow"]

# COMMAND ----------

# MAGIC %md
# MAGIC ### 3.1 Encodage des Variables CatÃ©gorielles
# MAGIC 
# MAGIC Spark ML nÃ©cessite des **vecteurs numÃ©riques**. Pour les catÃ©gories :
# MAGIC 
# MAGIC 1. **StringIndexer** : "France" â†’ 0, "Allemagne" â†’ 1, ...
# MAGIC 2. **OneHotEncoder** : 0 â†’ [1,0,0,...], 1 â†’ [0,1,0,...], ...

# COMMAND ----------

# CrÃ©ation des StringIndexers (un par colonne catÃ©gorielle)
indexers = [
    StringIndexer(
        inputCol=c, 
        outputCol=f"{c}_idx",
        handleInvalid="keep"  # Garde les valeurs inconnues (safety)
    ) 
    for c in cat_cols
]

# CrÃ©ation des OneHotEncoders
encoders = [
    OneHotEncoder(
        inputCol=f"{c}_idx", 
        outputCol=f"{c}_ohe"
    ) 
    for c in cat_cols
]

print(f"âœ… {len(indexers)} indexers + {len(encoders)} encoders crÃ©Ã©s")

# COMMAND ----------

# MAGIC %md
# MAGIC ### 3.2 Assemblage des Features

# COMMAND ----------

# Colonnes finales Ã  assembler
feature_cols = [f"{c}_ohe" for c in cat_cols] + num_cols
print(f"ğŸ“‹ Features Ã  assembler : {feature_cols}")

# VectorAssembler : combine tout en un seul vecteur "features"
assembler = VectorAssembler(
    inputCols=feature_cols,
    outputCol="features"
)

# COMMAND ----------

# MAGIC %md
# MAGIC ### 3.3 ModÃ¨le : Logistic Regression
# MAGIC 
# MAGIC **Pourquoi Logistic Regression ?**
# MAGIC - âœ… Simple et interprÃ©table
# MAGIC - âœ… Rapide Ã  entraÃ®ner
# MAGIC - âœ… Bonne baseline pour la classification binaire
# MAGIC - âœ… ProbabilitÃ©s calibrÃ©es

# COMMAND ----------

# CrÃ©ation du modÃ¨le
lr = LogisticRegression(
    featuresCol="features",
    labelCol="high_value_order",
    maxIter=100,
    regParam=0.01  # LÃ©gÃ¨re rÃ©gularisation L2
)

# COMMAND ----------

# MAGIC %md
# MAGIC ### 3.4 Assemblage du Pipeline Complet

# COMMAND ----------

# Pipeline = sÃ©quence d'Ã©tapes
pipeline = Pipeline(stages=indexers + encoders + [assembler, lr])

print("âœ… Pipeline crÃ©Ã© avec", len(pipeline.getStages()), "Ã©tapes")

# COMMAND ----------

# MAGIC %md
# MAGIC ## 4ï¸âƒ£ EntraÃ®nement du ModÃ¨le

# COMMAND ----------

# EntraÃ®nement (peut prendre 1-2 minutes sur 1.6M lignes)
print("ğŸš€ EntraÃ®nement en cours...")
model = pipeline.fit(train)
print("âœ… ModÃ¨le entraÃ®nÃ© !")

# COMMAND ----------

# MAGIC %md
# MAGIC ## 5ï¸âƒ£ Ã‰valuation du ModÃ¨le

# COMMAND ----------

# PrÃ©dictions sur le jeu de test
predictions = model.transform(test)

# COMMAND ----------

# AperÃ§u des prÃ©dictions
display(
    predictions.select(
        "country", "channel", "category", "price", "quantity",
        "high_value_order", "rawPrediction", "probability", "prediction"
    ).limit(20)
)

# COMMAND ----------

# MAGIC %md
# MAGIC ### 5.1 MÃ©trique : AUC (Area Under ROC Curve)
# MAGIC 
# MAGIC **InterprÃ©tation de l'AUC :**
# MAGIC - `0.5` = modÃ¨le alÃ©atoire (inutile)
# MAGIC - `0.7-0.8` = modÃ¨le acceptable
# MAGIC - `0.8-0.9` = bon modÃ¨le
# MAGIC - `> 0.9` = excellent modÃ¨le

# COMMAND ----------

from pyspark.ml.evaluation import BinaryClassificationEvaluator

# Ã‰valuateur AUC
evaluator_auc = BinaryClassificationEvaluator(
    labelCol="high_value_order",
    metricName="areaUnderROC"
)

auc = evaluator_auc.evaluate(predictions)
print(f"ğŸ“Š AUC (Area Under ROC) : {auc:.4f}")

# COMMAND ----------

# Ã‰valuateur PR-AUC (Area Under Precision-Recall Curve)
evaluator_pr = BinaryClassificationEvaluator(
    labelCol="high_value_order",
    metricName="areaUnderPR"
)

pr_auc = evaluator_pr.evaluate(predictions)
print(f"ğŸ“Š PR-AUC : {pr_auc:.4f}")

# COMMAND ----------

# MAGIC %md
# MAGIC ### 5.2 Matrice de Confusion
# MAGIC 
# MAGIC | | PrÃ©dit 0 | PrÃ©dit 1 |
# MAGIC |---|---|---|
# MAGIC | **RÃ©el 0** | TN (True Negative) | FP (False Positive) |
# MAGIC | **RÃ©el 1** | FN (False Negative) | TP (True Positive) |

# COMMAND ----------

from pyspark.sql.functions import col, when

# CrÃ©ation de la colonne de prÃ©diction binaire (seuil 0.5)
pred_binary = predictions.withColumn(
    "pred_label", 
    when(col("probability")[1] >= 0.5, 1).otherwise(0)
)

# Matrice de confusion
confusion_matrix = (
    pred_binary
    .groupBy("high_value_order", "pred_label")
    .count()
    .orderBy("high_value_order", "pred_label")
)

display(confusion_matrix)

# COMMAND ----------

# Calcul des mÃ©triques dÃ©taillÃ©es
from pyspark.sql.functions import sum as _sum

# Extraction des valeurs
cm_values = pred_binary.groupBy("high_value_order", "pred_label").count().collect()

# Parsing (attention Ã  l'ordre)
tp = fn = fp = tn = 0
for row in cm_values:
    if row["high_value_order"] == 1 and row["pred_label"] == 1:
        tp = row["count"]
    elif row["high_value_order"] == 1 and row["pred_label"] == 0:
        fn = row["count"]
    elif row["high_value_order"] == 0 and row["pred_label"] == 1:
        fp = row["count"]
    elif row["high_value_order"] == 0 and row["pred_label"] == 0:
        tn = row["count"]

# MÃ©triques
precision = tp / (tp + fp) if (tp + fp) > 0 else 0
recall = tp / (tp + fn) if (tp + fn) > 0 else 0
f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0
accuracy = (tp + tn) / (tp + tn + fp + fn)

print(f"""
ğŸ“Š MÃ©triques de Classification (seuil = 0.5)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
âœ… Accuracy  : {accuracy:.2%}
ğŸ¯ Precision : {precision:.2%}
ğŸ“ˆ Recall    : {recall:.2%}
âš–ï¸  F1-Score  : {f1:.2%}

ğŸ“‹ Matrice de Confusion
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
True Positives  (TP) : {tp:,}
True Negatives  (TN) : {tn:,}
False Positives (FP) : {fp:,}
False Negatives (FN) : {fn:,}
""")

# COMMAND ----------

# MAGIC %md
# MAGIC ### ğŸ’¡ InterprÃ©tation des MÃ©triques
# MAGIC 
# MAGIC | MÃ©trique | Signification MÃ©tier |
# MAGIC |----------|----------------------|
# MAGIC | **Precision** | "Quand je dis high-value, j'ai raison X% du temps" |
# MAGIC | **Recall** | "Je capture X% des vraies commandes high-value" |
# MAGIC | **F1-Score** | Ã‰quilibre entre precision et recall |
# MAGIC 
# MAGIC **Trade-off mÃ©tier** :
# MAGIC - Si coÃ»t FP Ã©levÃ© (offres gaspillÃ©es) â†’ optimiser Precision
# MAGIC - Si coÃ»t FN Ã©levÃ© (clients VIP ignorÃ©s) â†’ optimiser Recall

# COMMAND ----------

# MAGIC %md
# MAGIC ## 6ï¸âƒ£ Scoring : Utilisation OpÃ©rationnelle
# MAGIC 
# MAGIC Le modÃ¨le produit une **probabilitÃ©** d'Ãªtre high-value, utilisable pour :
# MAGIC - Prioriser le traitement des commandes
# MAGIC - Segmenter les clients
# MAGIC - DÃ©clencher des actions automatiques

# COMMAND ----------

from pyspark.sql.functions import round as spark_round

# Scoring de l'ensemble des donnÃ©es
scored = model.transform(ml_df).select(
    "country", "channel", "payment", "category", "product",
    "price", "quantity", "month", "dow",
    "high_value_order",
    spark_round(col("probability")[1], 4).alias("p_high_value")
)

# COMMAND ----------

# Top 20 commandes avec la plus forte probabilitÃ©
print("ğŸ† Top 20 commandes Ã  plus forte probabilitÃ© high-value :")
display(
    scored
    .orderBy(col("p_high_value").desc())
    .limit(20)
)

# COMMAND ----------

# Distribution des scores
print("ğŸ“Š Distribution des scores de probabilitÃ© :")
display(
    scored
    .withColumn("score_bucket", 
        when(col("p_high_value") < 0.2, "0-20%")
        .when(col("p_high_value") < 0.4, "20-40%")
        .when(col("p_high_value") < 0.6, "40-60%")
        .when(col("p_high_value") < 0.8, "60-80%")
        .otherwise("80-100%")
    )
    .groupBy("score_bucket")
    .count()
    .orderBy("score_bucket")
)

# COMMAND ----------

# MAGIC %md
# MAGIC ## 7ï¸âƒ£ InterprÃ©tation MÃ©tier
# MAGIC 
# MAGIC ### Quels facteurs influencent les commandes high-value ?

# COMMAND ----------

# Taux de high-value par pays
print("ğŸŒ Taux de commandes high-value par pays :")
display(
    scored
    .groupBy("country")
    .agg(
        count("*").alias("nb_commandes"),
        _sum("high_value_order").alias("nb_high_value"),
        spark_round(avg("p_high_value"), 3).alias("prob_moyenne")
    )
    .withColumn("taux_high_value", 
                spark_round(col("nb_high_value") / col("nb_commandes") * 100, 1))
    .orderBy(col("prob_moyenne").desc())
)

# COMMAND ----------

# Taux de high-value par canal
print("ğŸ“± Taux de commandes high-value par canal :")
display(
    scored
    .groupBy("channel")
    .agg(
        count("*").alias("nb_commandes"),
        spark_round(avg("p_high_value"), 3).alias("prob_moyenne"),
        spark_round(avg("high_value_order") * 100, 1).alias("taux_high_value_pct")
    )
    .orderBy(col("prob_moyenne").desc())
)

# COMMAND ----------

# Taux de high-value par catÃ©gorie
print("ğŸ“¦ Taux de commandes high-value par catÃ©gorie :")
display(
    scored
    .groupBy("category")
    .agg(
        count("*").alias("nb_commandes"),
        spark_round(avg("p_high_value"), 3).alias("prob_moyenne"),
        spark_round(avg("high_value_order") * 100, 1).alias("taux_high_value_pct")
    )
    .orderBy(col("prob_moyenne").desc())
)

# COMMAND ----------

# MAGIC %md
# MAGIC ### ğŸ“‹ Recommandations MÃ©tier
# MAGIC 
# MAGIC Sur la base de notre analyse, voici les actions recommandÃ©es :
# MAGIC 
# MAGIC 1. **Service Client Premium** :
# MAGIC    - Prioriser les commandes avec `p_high_value > 0.7`
# MAGIC    - DÃ©lai de rÃ©ponse rÃ©duit pour ces clients
# MAGIC 
# MAGIC 2. **Marketing CiblÃ©** :
# MAGIC    - Focus sur les catÃ©gories Ã  forte probabilitÃ© (Informatique, Ã‰lectronique)
# MAGIC    - Campagnes adaptÃ©es par canal (Web vs Mobile)
# MAGIC 
# MAGIC 3. **Logistique** :
# MAGIC    - Anticiper les pics (novembre/dÃ©cembre)
# MAGIC    - Stock renforcÃ© sur les produits high-value

# COMMAND ----------

# MAGIC %md
# MAGIC ## 8ï¸âƒ£ Extensions (Niveau AvancÃ©)
# MAGIC 
# MAGIC ### 8.1 Tracking avec MLflow

# COMMAND ----------

# MAGIC %md
# MAGIC ```python
# MAGIC import mlflow
# MAGIC import mlflow.spark
# MAGIC 
# MAGIC # DÃ©marrer un run MLflow
# MAGIC with mlflow.start_run(run_name="logistic_regression_v1"):
# MAGIC     # Log des paramÃ¨tres
# MAGIC     mlflow.log_param("model_type", "LogisticRegression")
# MAGIC     mlflow.log_param("max_iter", 100)
# MAGIC     mlflow.log_param("reg_param", 0.01)
# MAGIC     
# MAGIC     # Log des mÃ©triques
# MAGIC     mlflow.log_metric("auc", auc)
# MAGIC     mlflow.log_metric("precision", precision)
# MAGIC     mlflow.log_metric("recall", recall)
# MAGIC     mlflow.log_metric("f1_score", f1)
# MAGIC     
# MAGIC     # Log du modÃ¨le
# MAGIC     mlflow.spark.log_model(model, "model")
# MAGIC     
# MAGIC     print("âœ… Run MLflow enregistrÃ© !")
# MAGIC ```

# COMMAND ----------

# MAGIC %md
# MAGIC ### 8.2 ModÃ¨le Alternatif : Random Forest

# COMMAND ----------

# Pour tester un modÃ¨le plus puissant (dÃ©commentez)

# from pyspark.ml.classification import RandomForestClassifier
# 
# rf = RandomForestClassifier(
#     featuresCol="features",
#     labelCol="high_value_order",
#     numTrees=100,
#     maxDepth=10
# )
# 
# pipeline_rf = Pipeline(stages=indexers + encoders + [assembler, rf])
# model_rf = pipeline_rf.fit(train)
# 
# pred_rf = model_rf.transform(test)
# auc_rf = evaluator_auc.evaluate(pred_rf)
# print(f"ğŸ“Š AUC Random Forest : {auc_rf:.4f}")

# COMMAND ----------

# MAGIC %md
# MAGIC ### 8.3 Cross-Validation

# COMMAND ----------

# Pour une Ã©valuation plus robuste (dÃ©commentez)

# from pyspark.ml.tuning import CrossValidator, ParamGridBuilder
# 
# # Grille de paramÃ¨tres
# paramGrid = (ParamGridBuilder()
#     .addGrid(lr.regParam, [0.001, 0.01, 0.1])
#     .addGrid(lr.maxIter, [50, 100])
#     .build())
# 
# # Cross-validator
# cv = CrossValidator(
#     estimator=pipeline,
#     estimatorParamMaps=paramGrid,
#     evaluator=evaluator_auc,
#     numFolds=3
# )
# 
# cv_model = cv.fit(train)
# print(f"ğŸ“Š Meilleur AUC CV : {max(cv_model.avgMetrics):.4f}")

# COMMAND ----------

# MAGIC %md
# MAGIC ## âœ… SynthÃ¨se Notebook 3
# MAGIC 
# MAGIC ### Ce que nous avons accompli
# MAGIC 
# MAGIC | Ã‰tape | RÃ©sultat |
# MAGIC |-------|----------|
# MAGIC | Pipeline ML | Encodage + Assemblage + ModÃ¨le |
# MAGIC | EntraÃ®nement | LogisticRegression sur 1.6M lignes |
# MAGIC | Ã‰valuation | AUC, Precision, Recall, F1 |
# MAGIC | Scoring | ProbabilitÃ©s pour chaque commande |
# MAGIC | InterprÃ©tation | Recommandations mÃ©tier actionnables |
# MAGIC 
# MAGIC ### Messages clÃ©s
# MAGIC 
# MAGIC 1. **Pipeline** = reproductibilitÃ© et dÃ©ploiement simplifiÃ©
# MAGIC 2. **Ã‰valuation** = toujours sur donnÃ©es non vues (test set)
# MAGIC 3. **InterprÃ©tation** = traduire les scores en dÃ©cisions business
# MAGIC 
# MAGIC ---
# MAGIC 
# MAGIC ## ğŸ“ SynthÃ¨se Fil Rouge Complet
# MAGIC 
# MAGIC | Notebook | CompÃ©tence | Livrable |
# MAGIC |----------|------------|----------|
# MAGIC | **1 - Big Data** | IngÃ©rer & traiter Ã  l'Ã©chelle | Table Delta optimisÃ©e |
# MAGIC | **2 - Data Science** | Explorer & fiabiliser | Dataset ML avec cible |
# MAGIC | **3 - Machine Learning** | ModÃ©liser & Ã©valuer | ModÃ¨le + scores + recommandations |
# MAGIC 
# MAGIC > ğŸ’¡ **Le Data Scientist complet** maÃ®trise les 3 Ã©tapes : de la donnÃ©e brute Ã  la dÃ©cision business.

# COMMAND ----------

# MAGIC %md
# MAGIC ---
# MAGIC ## ğŸ“ Exercices Pratiques
# MAGIC 
# MAGIC ### Exercice 1 : Seuil Optimal
# MAGIC Au lieu de 0.5, trouvez le seuil qui maximise le F1-Score.
# MAGIC 
# MAGIC ### Exercice 2 : Comparaison de ModÃ¨les
# MAGIC EntraÃ®nez un GBTClassifier et comparez l'AUC avec LogisticRegression.
# MAGIC 
# MAGIC ### Exercice 3 : Feature Importance
# MAGIC Pour un RandomForest, affichez les features les plus importantes.

# COMMAND ----------

# ğŸ¯ EXERCICE 1 : Votre code ici
# Indice : testez plusieurs seuils [0.3, 0.4, 0.5, 0.6, 0.7] et calculez F1 pour chacun



# COMMAND ----------

# ğŸ¯ EXERCICE 2 : Votre code ici
# from pyspark.ml.classification import GBTClassifier
# Indice : mÃªme pipeline, remplacer lr par GBTClassifier



# COMMAND ----------

# ğŸ¯ EXERCICE 3 : Votre code ici
# Indice : model.stages[-1].featureImportances



# COMMAND ----------

# MAGIC %md
# MAGIC ---
# MAGIC 
# MAGIC ## ğŸ† FÃ©licitations !
# MAGIC 
# MAGIC Vous avez complÃ©tÃ© le fil rouge **Big Data â†’ Data Science â†’ Machine Learning** !
# MAGIC 
# MAGIC Vous savez maintenant :
# MAGIC - âœ… IngÃ©rer des donnÃ©es massives avec Spark
# MAGIC - âœ… Les explorer et les prÃ©parer pour le ML
# MAGIC - âœ… Construire et Ã©valuer un modÃ¨le de classification
# MAGIC - âœ… Produire des recommandations mÃ©tier actionnables
